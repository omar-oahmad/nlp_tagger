{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "from functools import reduce\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "# specify GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8502091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==2.3.0 in d:\\programming\\anaconda\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (2021.8.3)\n",
      "Requirement already satisfied: numpy in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (1.20.3)\n",
      "Requirement already satisfied: tqdm in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (4.62.3)\n",
      "Requirement already satisfied: requests in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (0.0.53)\n",
      "Requirement already satisfied: boto3 in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (1.23.6)\n",
      "Requirement already satisfied: sentencepiece in d:\\programming\\anaconda\\lib\\site-packages (from transformers==2.3.0) (0.1.96)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in d:\\programming\\anaconda\\lib\\site-packages (from boto3->transformers==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in d:\\programming\\anaconda\\lib\\site-packages (from boto3->transformers==2.3.0) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.6 in d:\\programming\\anaconda\\lib\\site-packages (from boto3->transformers==2.3.0) (1.26.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in d:\\programming\\anaconda\\lib\\site-packages (from botocore<1.27.0,>=1.26.6->boto3->transformers==2.3.0) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in d:\\programming\\anaconda\\lib\\site-packages (from botocore<1.27.0,>=1.26.6->boto3->transformers==2.3.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programming\\anaconda\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.6->boto3->transformers==2.3.0) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programming\\anaconda\\lib\\site-packages (from requests->transformers==2.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programming\\anaconda\\lib\\site-packages (from requests->transformers==2.3.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\programming\\anaconda\\lib\\site-packages (from requests->transformers==2.3.0) (2.0.4)\n",
      "Requirement already satisfied: joblib in d:\\programming\\anaconda\\lib\\site-packages (from sacremoses->transformers==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: click in d:\\programming\\anaconda\\lib\\site-packages (from sacremoses->transformers==2.3.0) (8.0.3)\n",
      "Requirement already satisfied: colorama in d:\\programming\\anaconda\\lib\\site-packages (from click->sacremoses->transformers==2.3.0) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c36869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ab3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Covid_Papers.csv')\n",
    "df.drop(\"Unnamed: 0\", axis =1, inplace = True)\n",
    "df['abstract'] = df['title'] + ' ' + df['abstract']\n",
    "df.drop(\"title\", axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0187f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(val):\n",
    "    val = val.replace(\"'\",\"\")\n",
    "    val = val.strip('][').split(', ')\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7eefa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63400e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = []\n",
    "for i in range(len(df)):\n",
    "    tags_list = tags_list + df['tags'][i]\n",
    "tags_list = list(set(tags_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56599e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = [list(filter(None, df['tags'][i])) for i in range(len(df))]\n",
    "df = df[df['tags'].map(lambda d: len(d)) > 0]\n",
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99dc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns = df.columns.tolist() + tags_list, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c7207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(df)):\n",
    "    for tag in (df['tags'][a]):\n",
    "        df.at[a,tag] = 1\n",
    "df.drop(\"tags\", axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e2639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846f565a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>Hemobilia / etiology*</th>\n",
       "      <th>Computer-Assisted* / methods</th>\n",
       "      <th>Non-alcoholic Fatty Liver Disease / complications</th>\n",
       "      <th>Ulcerative / therapy*</th>\n",
       "      <th>Cognitive Dysfunction* / virology</th>\n",
       "      <th>Hearing Loss* / etiology</th>\n",
       "      <th>Adenosine Deaminase / immunology</th>\n",
       "      <th>Respiration Disorders / etiology</th>\n",
       "      <th>Catalytic Domain</th>\n",
       "      <th>...</th>\n",
       "      <th>Pandemics / statistics &amp;amp; numerical data*</th>\n",
       "      <th>Membrane Proteins / metabolism</th>\n",
       "      <th>Adenosine / genetics</th>\n",
       "      <th>Respiratory Syncytial Virus Infections / mortality</th>\n",
       "      <th>Interferon Type I / genetics</th>\n",
       "      <th>Acute Lung Injury / drug therapy*</th>\n",
       "      <th>Human / epidemiology</th>\n",
       "      <th>Female / therapy</th>\n",
       "      <th>Drug Delivery Systems / methods*</th>\n",
       "      <th>Anorexia Nervosa* / epidemiology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real-World Experience with COVID-19  Including...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Successful outcome of pre-engraftment COVID-19...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The impact of COVID-19 on oncology professiona...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICU admission and mortality classifiers for CO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical evaluation of nasopharyngeal  midturb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>Hypersensitivity Reactions to Vaccines  Curren...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>Rooming-in  Breastfeeding and Neonatal Follow-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>Acute Abducens Nerve Palsy Following the Secon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>Planning and Implementing the Protocol for Psy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>Prolonged corrected QT interval in hospitalize...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5473 rows × 11388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               abstract  \\\n",
       "0     Real-World Experience with COVID-19  Including...   \n",
       "1     Successful outcome of pre-engraftment COVID-19...   \n",
       "2     The impact of COVID-19 on oncology professiona...   \n",
       "3     ICU admission and mortality classifiers for CO...   \n",
       "4     Clinical evaluation of nasopharyngeal  midturb...   \n",
       "...                                                 ...   \n",
       "5468  Hypersensitivity Reactions to Vaccines  Curren...   \n",
       "5469  Rooming-in  Breastfeeding and Neonatal Follow-...   \n",
       "5470  Acute Abducens Nerve Palsy Following the Secon...   \n",
       "5471  Planning and Implementing the Protocol for Psy...   \n",
       "5472  Prolonged corrected QT interval in hospitalize...   \n",
       "\n",
       "      Hemobilia / etiology*  Computer-Assisted* / methods  \\\n",
       "0                         0                             0   \n",
       "1                         0                             0   \n",
       "2                         0                             0   \n",
       "3                         0                             0   \n",
       "4                         0                             0   \n",
       "...                     ...                           ...   \n",
       "5468                      0                             0   \n",
       "5469                      0                             0   \n",
       "5470                      0                             0   \n",
       "5471                      0                             0   \n",
       "5472                      0                             0   \n",
       "\n",
       "      Non-alcoholic Fatty Liver Disease / complications  \\\n",
       "0                                                     0   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "5468                                                  0   \n",
       "5469                                                  0   \n",
       "5470                                                  0   \n",
       "5471                                                  0   \n",
       "5472                                                  0   \n",
       "\n",
       "      Ulcerative / therapy*  Cognitive Dysfunction* / virology  \\\n",
       "0                         0                                  0   \n",
       "1                         0                                  0   \n",
       "2                         0                                  0   \n",
       "3                         0                                  0   \n",
       "4                         0                                  0   \n",
       "...                     ...                                ...   \n",
       "5468                      0                                  0   \n",
       "5469                      0                                  0   \n",
       "5470                      0                                  0   \n",
       "5471                      0                                  0   \n",
       "5472                      0                                  0   \n",
       "\n",
       "      Hearing Loss* / etiology  Adenosine Deaminase / immunology  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "2                            0                                 0   \n",
       "3                            0                                 0   \n",
       "4                            0                                 0   \n",
       "...                        ...                               ...   \n",
       "5468                         0                                 0   \n",
       "5469                         0                                 0   \n",
       "5470                         0                                 0   \n",
       "5471                         0                                 0   \n",
       "5472                         0                                 0   \n",
       "\n",
       "      Respiration Disorders / etiology  Catalytic Domain  ...  \\\n",
       "0                                    0                 0  ...   \n",
       "1                                    0                 0  ...   \n",
       "2                                    0                 0  ...   \n",
       "3                                    0                 0  ...   \n",
       "4                                    0                 0  ...   \n",
       "...                                ...               ...  ...   \n",
       "5468                                 0                 0  ...   \n",
       "5469                                 0                 0  ...   \n",
       "5470                                 0                 0  ...   \n",
       "5471                                 0                 0  ...   \n",
       "5472                                 0                 0  ...   \n",
       "\n",
       "      Pandemics / statistics &amp; numerical data*  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "5468                                             0   \n",
       "5469                                             0   \n",
       "5470                                             0   \n",
       "5471                                             0   \n",
       "5472                                             0   \n",
       "\n",
       "      Membrane Proteins / metabolism  Adenosine / genetics  \\\n",
       "0                                  0                     0   \n",
       "1                                  0                     0   \n",
       "2                                  0                     0   \n",
       "3                                  0                     0   \n",
       "4                                  0                     0   \n",
       "...                              ...                   ...   \n",
       "5468                               0                     0   \n",
       "5469                               0                     0   \n",
       "5470                               0                     0   \n",
       "5471                               0                     0   \n",
       "5472                               0                     0   \n",
       "\n",
       "      Respiratory Syncytial Virus Infections / mortality  \\\n",
       "0                                                     0    \n",
       "1                                                     0    \n",
       "2                                                     0    \n",
       "3                                                     0    \n",
       "4                                                     0    \n",
       "...                                                 ...    \n",
       "5468                                                  0    \n",
       "5469                                                  0    \n",
       "5470                                                  0    \n",
       "5471                                                  0    \n",
       "5472                                                  0    \n",
       "\n",
       "      Interferon Type I / genetics  Acute Lung Injury / drug therapy*  \\\n",
       "0                                0                                  0   \n",
       "1                                0                                  0   \n",
       "2                                0                                  0   \n",
       "3                                0                                  0   \n",
       "4                                0                                  0   \n",
       "...                            ...                                ...   \n",
       "5468                             0                                  0   \n",
       "5469                             0                                  0   \n",
       "5470                             0                                  0   \n",
       "5471                             0                                  0   \n",
       "5472                             0                                  0   \n",
       "\n",
       "      Human / epidemiology  Female / therapy  \\\n",
       "0                        0                 0   \n",
       "1                        0                 0   \n",
       "2                        0                 0   \n",
       "3                        0                 0   \n",
       "4                        0                 0   \n",
       "...                    ...               ...   \n",
       "5468                     0                 0   \n",
       "5469                     0                 0   \n",
       "5470                     0                 0   \n",
       "5471                     0                 0   \n",
       "5472                     0                 0   \n",
       "\n",
       "      Drug Delivery Systems / methods*  Anorexia Nervosa* / epidemiology  \n",
       "0                                    0                                 0  \n",
       "1                                    0                                 0  \n",
       "2                                    0                                 0  \n",
       "3                                    0                                 0  \n",
       "4                                    0                                 0  \n",
       "...                                ...                               ...  \n",
       "5468                                 0                                 0  \n",
       "5469                                 0                                 0  \n",
       "5470                                 0                                 0  \n",
       "5471                                 0                                 0  \n",
       "5472                                 0                                 0  \n",
       "\n",
       "[5473 rows x 11388 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd3d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"IwannaCry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f4fa50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_split = 0.1\n",
    "\n",
    "# Initial train and test split.\n",
    "df_train, df_test = train_test_split(df, test_size=test_split)\n",
    "\n",
    "# Splitting the test set further into validation\n",
    "# and new test sets.\n",
    "df_val = df_test.sample(frac=0.5)\n",
    "df_test.drop(df_val.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fff65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d5c8e78dd24e4592173d5e8e28524a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=True)\n",
    "MAX_LEN = 128\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_seq_len = 128):\n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in tqdm(sentences):\n",
    "        tokenized_sentence = tokenizer.encode(\n",
    "                            sentence,                  # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_seq_len,  # Truncate all sentences.\n",
    "                    )\n",
    "        \n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "\n",
    "    return tokenized_sentences\n",
    "\n",
    "def create_attention_masks(tokenized_and_padded_sentences):\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in tokenized_and_padded_sentences:\n",
    "        att_mask = [int(token_id > 0) for token_id in sentence]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return np.asarray(attention_masks)\n",
    "\n",
    "input_ids = tokenize_sentences(df_train['abstract'], tokenizer, MAX_LEN)\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "attention_masks = create_attention_masks(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "734d1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = df_train.columns[1:]\n",
    "labels =  df_train[label_cols].values\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=0, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=0, test_size=0.1)\n",
    "\n",
    "train_size = len(df_train)\n",
    "validation_size = len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c1aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NR_EPOCHS = 1\n",
    "\n",
    "def create_dataset(data_tuple, epochs=1, batch_size=32, buffer_size=10000, train=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data_tuple)\n",
    "    if train:\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if train:\n",
    "        dataset = dataset.prefetch(1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset((train_inputs, train_masks, train_labels), epochs=NR_EPOCHS, batch_size=BATCH_SIZE)\n",
    "validation_dataset = create_dataset((validation_inputs, validation_masks, validation_labels), epochs=NR_EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a76de17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3b94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71bd658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenization in d:\\programming\\anaconda\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: regex in d:\\programming\\anaconda\\lib\\site-packages (from tokenization) (2021.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1299c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using C:\\Users\\moaaz\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tokenization\n",
    "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a75bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "class BertClassifier(tf.keras.Model):    \n",
    "    def __init__(self, bert: TFBertModel, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.classifier = Dense(num_classes, activation='sigmoid')\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None):\n",
    "        outputs = self.bert(input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids,\n",
    "                               position_ids=position_ids,\n",
    "                               head_mask=head_mask)\n",
    "        cls_output = outputs[1]\n",
    "        cls_output = self.classifier(cls_output)\n",
    "                \n",
    "        return cls_output\n",
    "\n",
    "model = BertClassifier(TFBertModel.from_pretrained(bert_model_name), len(label_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b33827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import create_optimizer\n",
    "\n",
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "validation_steps = validation_size // BATCH_SIZE\n",
    "\n",
    "# | Loss Function\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "validation_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "# | Optimizer (with 1-cycle-policy)\n",
    "warmup_steps = steps_per_epoch // 3\n",
    "total_steps = steps_per_epoch * NR_EPOCHS - warmup_steps\n",
    "optimizer = create_optimizer(init_lr=2e-5, num_train_steps=total_steps, num_warmup_steps=warmup_steps)\n",
    "\n",
    "# | Metrics\n",
    "train_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n",
    "validation_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2816a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, token_ids, masks, labels):\n",
    "    labels = tf.dtypes.cast(labels, tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(token_ids, attention_mask=masks)\n",
    "        loss = loss_object(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables), 1.0)\n",
    "\n",
    "    train_loss(loss)\n",
    "\n",
    "    for i, auc in enumerate(train_auc_metrics):\n",
    "        auc.update_state(labels[:,i], predictions[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6db7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def validation_step(model, token_ids, masks, labels):\n",
    "    labels = tf.dtypes.cast(labels, tf.float32)\n",
    "\n",
    "    predictions = model(token_ids, attention_mask=masks, training=False)\n",
    "    v_loss = loss_object(labels, predictions)\n",
    "\n",
    "    validation_loss(v_loss)\n",
    "    for i, auc in enumerate(validation_auc_metrics):\n",
    "        auc.update_state(labels[:,i], predictions[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8514d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, val_dataset, train_steps_per_epoch, val_steps_per_epoch, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print('=' * 50, f\"EPOCH {epoch}\", '=' * 50)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for i, (token_ids, masks, labels) in enumerate(tqdm(train_dataset, total=train_steps_per_epoch)):\n",
    "            train_step(model, token_ids, masks, labels)\n",
    "            if i % 1000 == 0:\n",
    "                print(f'\\nTrain Step: {i}, Loss: {train_loss.result()}')\n",
    "                for i, label_name in enumerate(label_cols):\n",
    "                    print(f\"{label_name} roc_auc {train_auc_metrics[i].result()}\")\n",
    "                    train_auc_metrics[i].reset_states()\n",
    "        \n",
    "        for i, (token_ids, masks, labels) in enumerate(tqdm(val_dataset, total=val_steps_per_epoch)):\n",
    "            validation_step(model, token_ids, masks, labels)\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1}, Validation Loss: {validation_loss.result()}, Time: {time.time()-start}\\n')\n",
    "\n",
    "        for i, label_name in enumerate(label_cols):\n",
    "            print(f\"{label_name} roc_auc {validation_auc_metrics[i].result()}\")\n",
    "            validation_auc_metrics[i].reset_states()\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c583d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== EPOCH 0 ==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f427caf1af424f87500dc942e8d76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1' defined at (most recent call last):\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/3682669036.py\", line 1, in <module>\n      train(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=NR_EPOCHS)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1407868230.py\", line 8, in train\n      train_step(model, token_ids, masks, labels)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1489209131.py\", line 6, in train_step\n      predictions = model(token_ids, attention_mask=masks)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/4057089439.py\", line 12, in call\n      outputs = self.bert(input_ids,\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 690, in call\n      outputs = self.bert(inputs, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 550, in call\n      encoder_outputs = self.encoder([embedding_output, extended_attention_mask, head_mask], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 363, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 367, in call\n      layer_outputs = layer_module([hidden_states, attention_mask, head_mask[i]], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 345, in call\n      intermediate_output = self.intermediate(attention_output)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 311, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\activation.py\", line 57, in call\n      return self.activation(inputs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 68, in gelu\n      return x * cdf\nNode: 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1'\nDetected at node 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1' defined at (most recent call last):\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/3682669036.py\", line 1, in <module>\n      train(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=NR_EPOCHS)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1407868230.py\", line 8, in train\n      train_step(model, token_ids, masks, labels)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1489209131.py\", line 6, in train_step\n      predictions = model(token_ids, attention_mask=masks)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/4057089439.py\", line 12, in call\n      outputs = self.bert(input_ids,\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 690, in call\n      outputs = self.bert(inputs, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 550, in call\n      encoder_outputs = self.encoder([embedding_output, extended_attention_mask, head_mask], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 363, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 367, in call\n      layer_outputs = layer_module([hidden_states, attention_mask, head_mask[i]], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 345, in call\n      intermediate_output = self.intermediate(attention_output)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 311, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\activation.py\", line 57, in call\n      return self.activation(inputs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 68, in gelu\n      return x * cdf\nNode: 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[assert_greater_equal_424/Assert/AssertGuard/pivot_f/_9909/_17731]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_192415]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3960/3682669036.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_steps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNR_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3960/1407868230.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, val_dataset, train_steps_per_epoch, val_steps_per_epoch, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nTrain Step: {i}, Loss: {train_loss.result()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1' defined at (most recent call last):\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/3682669036.py\", line 1, in <module>\n      train(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=NR_EPOCHS)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1407868230.py\", line 8, in train\n      train_step(model, token_ids, masks, labels)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1489209131.py\", line 6, in train_step\n      predictions = model(token_ids, attention_mask=masks)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/4057089439.py\", line 12, in call\n      outputs = self.bert(input_ids,\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 690, in call\n      outputs = self.bert(inputs, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 550, in call\n      encoder_outputs = self.encoder([embedding_output, extended_attention_mask, head_mask], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 363, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 367, in call\n      layer_outputs = layer_module([hidden_states, attention_mask, head_mask[i]], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 345, in call\n      intermediate_output = self.intermediate(attention_output)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 311, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\activation.py\", line 57, in call\n      return self.activation(inputs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 68, in gelu\n      return x * cdf\nNode: 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1'\nDetected at node 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1' defined at (most recent call last):\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Programming\\Anaconda\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\Programming\\Anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/3682669036.py\", line 1, in <module>\n      train(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=NR_EPOCHS)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1407868230.py\", line 8, in train\n      train_step(model, token_ids, masks, labels)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/1489209131.py\", line 6, in train_step\n      predictions = model(token_ids, attention_mask=masks)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Local\\Temp/ipykernel_3960/4057089439.py\", line 12, in call\n      outputs = self.bert(input_ids,\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 690, in call\n      outputs = self.bert(inputs, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 550, in call\n      encoder_outputs = self.encoder([embedding_output, extended_attention_mask, head_mask], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 363, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 367, in call\n      layer_outputs = layer_module([hidden_states, attention_mask, head_mask[i]], training=training)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 345, in call\n      intermediate_output = self.intermediate(attention_output)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 311, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\moaaz\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\activation.py\", line 57, in call\n      return self.activation(inputs)\n    File \"D:\\Programming\\Anaconda\\lib\\site-packages\\transformers\\modeling_tf_bert.py\", line 68, in gelu\n      return x * cdf\nNode: 'tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[assert_greater_equal_424/Assert/AssertGuard/pivot_f/_9909/_17731]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node tf_bert_model/bert/encoder/layer_._1/intermediate/activation/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_192415]"
     ]
    }
   ],
   "source": [
    "train(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=NR_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca173933",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = tokenize_sentences(df_test['abstract'], tokenizer, MAX_LEN)\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "test_attention_masks = create_attention_masks(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8874e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 32\n",
    "test_steps = len(df_test) // TEST_BATCH_SIZE\n",
    "\n",
    "test_dataset = create_dataset((test_input_ids, test_attention_masks), batch_size=TEST_BATCH_SIZE, train=False, epochs=1)\n",
    "\n",
    "df_pred = pd.read_csv(subm_path, index_col='id')\n",
    "\n",
    "for i, (token_ids, masks) in enumerate(tqdm(test_dataset, total=test_steps)):\n",
    "    sample_ids = df_test.iloc[i*TEST_BATCH_SIZE:(i+1)*TEST_BATCH_SIZE]['id']\n",
    "    predictions = model(token_ids, attention_mask=masks).numpy()\n",
    "\n",
    "    df_pred.loc[sample_ids, label_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f952fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d73b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60169a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f129bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c0fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d57cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103fcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ec0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \n",
    "    # punctuations except -  \n",
    "    punc ='''?!.,:;_—[](){}'\"`~|\\/@#$%^&+=*'''\n",
    "    for i in text:\n",
    "        if i in punc:\n",
    "            text = text.replace(i, ' ')            \n",
    "    return text.strip()\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    # lower casing\n",
    "    text=text.lower()\n",
    "    \n",
    "    # stopword removal\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    \n",
    "    # lemmatization\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # removing words containing only numbers\n",
    "    text = re.sub(r'\\s[0-9]+\\s', '', text)\n",
    "    \n",
    "    # remove extra spaces\n",
    "    text = re.sub(\"\\s\\s+\", \" \", text)   \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(remove_punctuation)\n",
    "df['title']=df['title'].apply(preprocess)\n",
    "\n",
    "df['abstract']=df['abstract'].apply(remove_punctuation)\n",
    "df['abstract']=df['abstract'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(val):\n",
    "    val = val.replace(\"'\",\"\")\n",
    "    val = val.strip('][').split(', ')\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract'] = df['title'] + ' ' + df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there is no spaces in the empty elements. Example: ' ' -> ''\n",
    "for i in range(len(df)):\n",
    "    for j, word in enumerate(df['tags'][i]):\n",
    "        df['tags'][i][j] = df['tags'][i][j].strip()\n",
    "        \n",
    "# Mark None for the the keyword, covid-19 and humans, since almost all the abstracts have as keyword.\n",
    "# Mark None for the empty elements '' \n",
    "for i in range(len(df)):\n",
    "    for j, word in enumerate(df['tags'][i]):\n",
    "        if word == '':\n",
    "            df['tags'][i][j] = None\n",
    "            \n",
    "df['tags'] = [list(filter(None, df['tags'][i])) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d351aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of all the tags \n",
    "tags_list = []\n",
    "for i in range(len(df)):\n",
    "    tags_list = tags_list + df['tags'][i]\n",
    "\n",
    "# Counts for each unique keyword\n",
    "counter=collections.Counter(tags_list)\n",
    "print('Number of total unique tags: {}'.format(len(counter)))\n",
    "\n",
    "# Pull the 20 most common words\n",
    "most_common_words= [word for word, word_count in collections.Counter(tags_list).most_common(20)]\n",
    "print('20 most common tags: {}'.format(most_common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f65ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the most common tags and if abstract doesn't include any of the common tags, remove completely\n",
    "for i in range(len(df)):\n",
    "    for j, word in enumerate(df['tags'][i]):\n",
    "        if word not in most_common_words:\n",
    "            df['tags'][i][j] = None\n",
    "                 \n",
    "df['tags'] = [list(filter(None, df['tags'][i])) for i in range(len(df))]\n",
    "df = df[df['tags'].map(lambda d: len(d)) > 0]\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print('Number of total abstracts after removal: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = list(set(tags_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ccb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"title\", axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns = df.columns.tolist() + tags_list, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba21534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(df)):\n",
    "    for tag in (df['tags'][a]):\n",
    "        df.at[a,tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ff8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2135231",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008818f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
